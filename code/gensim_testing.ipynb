{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c579d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import json\n",
    "import gzip\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "import train as tr # library for TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e866f463",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_save_model(corpus: list, model_path: str, vs=5, wdw=2, mc=1, epch=10):\n",
    "    documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(corpus)]\n",
    "    # train model\n",
    "    model = Doc2Vec(documents, vector_size=vs, window=wdw, min_count=mc, epochs=epch, workers=28)\n",
    "    model.save(model_path)\n",
    "    return model\n",
    "\n",
    "def load_model(model_path):\n",
    "    return Doc2Vec.load(model_path)\n",
    "\n",
    "def get_top_n_query_similarities(doc2vec_model, query, top_n=10):\n",
    "    sdlq = query.split(' ')\n",
    "    print(sdlq)\n",
    "    query_tfidf = doc2vec_model.infer_vector(sdlq)\n",
    "    print(query_tfidf)\n",
    "    raise NotImplementedError\n",
    "    \n",
    "    print(doc2vec_model.vc.shape)\n",
    "    print(doc2vec_model.vc)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "369fd0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "token_filter = {\n",
    "    'python': tr.NOISE_TOKEN_PYTHON | tr.LOGIC_TOKEN_PYTHON | tr.SYNTAX_TOKEN_PYTHON,\n",
    "    'go': tr.NOISE_TOKEN_GO | tr.LOGIC_TOKEN_GO | tr.SYNTAX_TOKEN_GO,\n",
    "    'java': tr.NOISE_TOKEN_JAVA | tr.LOGIC_TOKEN_JAVA | tr.SYNTAX_TOKEN_JAVA,\n",
    "    'javascript': tr.NOISE_TOKEN_JS | tr.LOGIC_TOKEN_JS | tr.SYNTAX_TOKEN_JS\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "367674dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset = tr.load_language_dataset('python')\n",
    "cleaned_data = [tr.create_doc(x, tfilter=token_filter['python']) for x in raw_dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df4ce23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = train_and_save_model(cleaned_data, 'doc2vec_models/gensim_model')\n",
    "# model2 = train_and_save_model(cleaned_data, 'doc2vec_models/gensim_model_vs300,wdw5', vs=300, wdw=5)\n",
    "# model3 = train_and_save_model(cleaned_data, 'doc2vec_models/gensim_model_vs500_wdw15', vs=500, wdw=20)\n",
    "# model4 = train_and_save_model(cleaned_data, 'doc2vec_models/gensim_model_vs2000_wdw30_epoch30', vs=2000, wdw=30, epch=30)\n",
    "# model5 = train_and_save_model(cleaned_data, 'doc2vec_models/gensim_model_vs3000_wdw30_epoch30', vs=3000, wdw=30, epch=30)\n",
    "# do not have enough memory to run below\n",
    "# model6 = train_and_save_model(cleaned_data, 'doc2vec_models/gensim_model_vs5000_wdw30_epoch30', vs=5000, wdw=30, epch=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2df63f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gensim_model_vs3000_wdw30_epoch30',\n",
       " 'gensim_model_vs300,wdw5',\n",
       " 'gensim_model_vs2000_wdw30_epoch30.wv.vectors.npy',\n",
       " 'gensim_model',\n",
       " 'gensim_model_vs3000_wdw30_epoch30.wv.vectors.npy',\n",
       " 'gensim_model_vs2000_wdw30_epoch30.dv.vectors.npy',\n",
       " 'gensim_model_vs2000_wdw30_epoch30.syn1neg.npy',\n",
       " 'gensim_model_vs2000_wdw30_epoch30',\n",
       " 'gensim_model_vs3000_wdw30_epoch30.syn1neg.npy',\n",
       " 'gensim_model_vs300,wdw5.dv.vectors.npy',\n",
       " 'gensim_model_vs500_wdw15',\n",
       " 'gensim_model_vs3000_wdw30_epoch30.dv.vectors.npy',\n",
       " 'gensim_model_vs500_wdw15.dv.vectors.npy']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('doc2vec_models')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d787015",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f84e54f7",
   "metadata": {},
   "source": [
    "# Vectorspace output = 2000; wordwindow = 30 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b4ad50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "v2000wdw30 = load_model('doc2vec_models/gensim_model_vs2000_wdw30_epoch30')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0fe9ac35",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector = v2000wdw30.infer_vector(\"convert int to string\".split(' '), epochs=100)\n",
    "ms = v2000wdw30.dv.most_similar([query_vector])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fdcef28c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08777601271867752 src/python/pants/goal/run_tracker.py\n",
      "0.08639977872371674 python/spark_sklearn/base_search.py\n",
      "0.08386426419019699 js2py/legecy_translators/nparser.py\n",
      "0.07874813675880432 openquake/hazardlib/calc/stochastic.py\n",
      "0.07862395793199539 scanpy/preprocessing/_qc.py\n",
      "0.07692356407642365 historical/vpc/differ.py\n",
      "0.07614123076200485 drogher/package/ontrac.py\n",
      "0.0755046159029007 clear/database.py\n",
      "0.07528843730688095 samples/hello.py\n",
      "0.07510476559400558 satpy/composites/viirs.py\n"
     ]
    }
   ],
   "source": [
    "for x, sim in ms:\n",
    "    print(sim, raw_dataset[x]['path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7ae24b50",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'KeyedVectors' object has no attribute 'items'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-bd70f06d4ebe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mv2000wdw30\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyedVectors' object has no attribute 'items'"
     ]
    }
   ],
   "source": [
    "v2000wdw30.wv.items()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f3cf8d",
   "metadata": {},
   "source": [
    "# Vectorspace output = 500; wordwindow = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b6cf62",
   "metadata": {},
   "outputs": [],
   "source": [
    "v3000wdw30 = load_model('doc2vec_models/gensim_model_vs3000_wdw30_epoch30')\n",
    "query_vector = v500wdw15.infer_vector(\"convert int to string\".split(' '))\n",
    "print(v500wdw15.dv.most_similar([query_vector]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510b9d3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6d196e44",
   "metadata": {},
   "source": [
    "# Vectorspace output = 3000; wordwindow = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b947d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "v500wdw15 = load_model('doc2vec_models/gensim_model_vs500_wdw15')\n",
    "query_vector = v3000wdw30.infer_vector(\"convert int to string\".split(' '))\n",
    "print(v3000wdw30.dv.most_similar([query_vector]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a7c644",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea88b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector = v2000wdw30.infer_vector(\"convert int to string\".split(' '))\n",
    "print(v2000wdw30.dv.most_similar([query_vector]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677289e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.infer_vector(\"convert in to string\".split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da904bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "qv = m1.infer_vector(\"convert int into string\".split(' '))\n",
    "m1.dv.most_similar([qv])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e5d7fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "m1.dv[555998]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1d3692",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_dataset[555998]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5b3c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "qv = m2.infer_vector(\"convert int into string\".split(' '))\n",
    "res = m2.dv.most_similar([qv], topn=20)\n",
    "for ind, sim in res:\n",
    "    print(sim, raw_dataset[ind]['function'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e2dc12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "qv = model3.infer_vector(\"convert int to string\".split(' '))\n",
    "res = model3.dv.most_similar([qv], topn=20)\n",
    "for ind, sim in res:\n",
    "    print(sim, raw_dataset[ind]['function'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "149b2e82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc64922b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eba8636e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('doc2vec_models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75b1c9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_queries_and_evaluate_doc2vec(output, \n",
    "                                    queries_path='evaluation_results/queries.csv', \n",
    "                                    language='python', \n",
    "                                    top_n=5, \n",
    "                                    tfilter=tr.NOISE_TOKEN_PYTHON):\n",
    "    print('---------preprocessing dataset---------')\n",
    "    raw_dataset = tr.load_language_dataset(language)\n",
    "    cleaned_data = [tr.create_doc(x, tfilter=tfilter) for x in raw_dataset]\n",
    "    \n",
    "    # train gensim\n",
    "    print('---------training model---------')\n",
    "    vectorizer = TfidfVectorizer(min_df=mindf, max_df=maxdf)\n",
    "    X = vectorizer.fit_transform(cleaned_data)\n",
    "    \n",
    "    # generate file mapping query to result - why is this the most complicated part...\n",
    "    print('---------running queries---------')\n",
    "    queries = list(pd.read_csv(queries_path)['query'])\n",
    "    num_queries = len(queries)\n",
    "    \n",
    "    # avoid excessive appending\n",
    "    # langs = [language] * top_n * num_queries #TODO: DELETE\n",
    "    qs = [None] * top_n * num_queries\n",
    "    m_urls = [None] * top_n * num_queries\n",
    "    snippets = [None] * top_n * num_queries\n",
    "\n",
    "    for ind, query in enumerate(queries):\n",
    "        print('{}: executing query: {}'.format(ind, query))\n",
    "        top_n_indices = get_top_n_query_similarities(vectorizer, X, query, top_n=top_n)\n",
    "        \n",
    "        for ind2, close_ind in enumerate(top_n_indices):\n",
    "            li = (ind * top_n) + ind2\n",
    "            m_urls[li] = raw_dataset[close_ind]['url']\n",
    "            snippets[li] = raw_dataset[close_ind]['function']\n",
    "            qs[li] = query\n",
    "\n",
    "    pd.DataFrame.from_dict({'model_name': 'tfidf_{}_{}_{}'.format(language, mindf, maxdf), \n",
    "                            'query': qs, \n",
    "                            'language': language,\n",
    "                            'function': snippets,\n",
    "                            'url': m_urls}).to_csv(output, index=False)\n",
    "    print('done')\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ea1e0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8377d7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in ['python', 'go', 'java', 'javascript']:\n",
    "    empty_filter_fname = 'evaluation_results/doc2vec/gensim_{}_nofilter.csv'.format(lang)\n",
    "    print(\"generating {}\".format(empty_filter_fname))\n",
    "    if os.path.exists(empty_filter_fname):\n",
    "        print('skipping because {} already exists - skipping'.format(empty_filter_fname))\n",
    "        continue\n",
    "    \n",
    "    load_queries_and_evaluate_word2vec(empty_filter_fname, language=lang, top_n=100, tfilter=set())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cad3a340",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
